---
title: "SUPERSTORE SALES PREDICTION BY USING MACHINE LEARNING MODEL"
author: "DANIEL (S2115750), VIRGIL (S2136594), YUEN HERN (S2121801), SYAKIRAH (S2132021)"
date: "16th June 2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<br />

![](img/pic1.jpg)

With growing demands and cut-throat competitions in the market, a Superstore Giant is seeking your knowledge in understanding what works best for them. They would like to understand which products, regions, categories and customer segments they should target or avoid.

They also want to have a Regression model to predict Sales or Profit.
<br />
<br />

### 1) Load Library
The libraries for the installed packages are loaded.
```{r, warning=FALSE, error=FALSE, message=FALSE}
library(readxl)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(ggrepel)
library(forcats)
library(scales)
library(superml)
library(corrplot)
library(reshape2)
library(broom)
library(ggpubr)
library(caret)
library(rpart)
library(rpart.plot)
```
<br />

### 2) Import Data
Firstly, let's get the dataset from XLS file. In the XLS file, there are 3 sheets:

-   Orders: List of transactions
-   Returns: List of items returned
-   People: List of sales person for West, East, Central and South
```{r}
df_order = read_xls('superstorev2.xls', sheet = 'Orders', col_names = TRUE)
df_return = read_xls('superstorev2.xls', sheet='Returns', col_names = TRUE)
df_people = read_xls('superstorev2.xls', sheet='People', col_names = TRUE)
```


#### <span style="text-decoration:underline">  Viewing data</span>
"Order" dataframe:
```{r}
head(df_order)
```

"Return" dataframe:
```{r}
head(df_return)
```

"People" dataframe:
```{r}
head(df_people)
```
<br />

### 3) Data Pre-processing
#### <span style="text-decoration:underline">  Merging "Return" and "People" dataframe into "Order" dataframe</span>
We merge `df_return$Returned` and `df_people$Person` into `d_orderf$Returned` and `df_order$Person` respectively, using full join to retain all values and rows.

```{r}
df = dplyr::full_join(df_order, df_return, by="Order ID")

df$`Order Date` = as.Date.character(df$`Order Date`, format="%Y-%m-%d")
df$`Ship Date` = as.Date(df$`Ship Date`, format="%Y-%m-%d")
df
```
After all the dataset are merged, `df` will be the dataset we use for this project.

<br />

#### <span style="text-decoration:underline">  Validate the data</span>
The structure of the dataset is checked.
```{r}
str(df)
```
The “Order” dataframe is 9994 instances and 22 features. Now check the summary of the “Order” dataframe.

<br />

#### <span style="text-decoration:underline">  Data Summary</span>
```{r}
summary(df)
```
What piqued interest was the statistics in Sales, Quantity, Discount and Profit column. From there, we know that:

-   Sales range from USD 0.44 to USD 22,638.48 per transaction; the average sales closed is USD 229.86 while a typical sale closed is USD 54.49
-   Quantity sold range from 1 to 14 items per transaction; typically each transaction sold around 3 to 4 items.
-   Discount range from USD 0 to USD 0.80, meaning this shop only give minimal discounts to customers.
-   Profit range from a loss USD -6,599.98 to a profit of USD 8,399.98. The average profit per transaction is USD 28.66 but we know most of the profit is lower than that due to median lower than mean.
-   On top of that, we also noticed that R is not able to identify which one is datetime format as they are parsed as characters.
<br />
<br />

#### <span style="text-decoration:underline">  Drop Unnecessary Column</span>

```{r, warning=FALSE, error=FALSE, message=FALSE}
drop<-c('Order Date','Ship Date','Row ID','Order ID','Customer ID','Customer Name','Postal Code', 'Product Name','Product ID','Country')

df <- df[,!(names(df) %in% drop)]
head(df)
```
<br />

#### <span style="text-decoration:underline">  Checking for any missing data</span>

Next, we check for missing value. The data set is checked for any non-availability (NA). This is because missing value is  dirty and might result in affecting out analysis.

```{r}
colSums(is.na(df))
```

There are missing values spotted inside `df`. Based on the results, we can see that there are few variables that contain NA value. They are Ship Mode and Discount. Ship Mode has 33 missing values, while Discount has 42 missing values. These missing value will be handled accordingly. 

<br />



#### <span style="text-decoration:underline">  Imputation (Using mode & median)</span>
We know that Ship Mode is in nominal pattern. Hence, we will handle the missing data by using imputation by mode. Meanwhile, for Discount, it is a numerical data. Hence, the missing data will be handled by using imputation by median.

```{r}
df<-as.data.frame(df)

getmode <- function(v){
  v=v[nchar(as.character(v))>0]
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}

df[sapply(df, is.character)] <- lapply(df[sapply(df, is.character)], function(x) ifelse(is.na(x) == TRUE, getmode(x), x))
df[sapply(df, is.character)] <- lapply(df[sapply(df, is.character)], as.factor)

df$Discount[is.na(df$Discount)]<-median(df$Discount,na.rm=TRUE)

df$Returned<-df$Returned[is.na(df$Returned)]<-'No'

colSums(is.na(df))

```
From the results, all columns illustrate 0 from any NA value. This show that all missing value had been handled properly. After missing value is cattered, the pattern of the data is studied.


<br />

#### <span style="text-decoration:underline">  Check Value Pattern Consistency</span>
**(Numerical data)** <br />
Numerical data in the dataset includes Sale, Quantity, Discount, and Profit. The pattern for the numerical data is studied. The aim is to determine for any irrelevant pattern in the dataset. To do so, histogram is plotted.

```{r}
hist(df$Discount)
hist(df$Quantity)
hist(df$Profit)
hist(df$Sales)
```

From the histogram, there is weird value in Quantity. This is because quantity should be in a positive whole value. It cannot be negative because this variable indicate the number of product. This is may be due to inputation error. So, removing it would be good since the amount of error in this variable is really small. Our dataset is big, removing small portion of error data will not affecting the whole pattern and orientation of the dataset.<br />
<br />
**The rows of the error data are removed:**

```{r}
df <- df[df$Quantity >= 0, ]
hist(df$Quantity)
```
<br />
From the results, it shows that the rows containing error value is removed successfully.

<br />
**(Categorical data)** <br />
Categorical data in this dataset includes Ship Mode, Segment, Country, City, State, Region, Category, and Sub-Category. The value pattern consistency is determined by counting the frequency distribution for each of the variable. Any weird naming value or redundancy can be determined from this method.

```{r}
table(df$`Ship Mode`)
table(df$Segment)
table(df$Country)
table(df$City)
table(df$State)
table(df$Region)
table(df$Category)
table(df$`Sub-Category`)

```
<br />
From the results, State have some value redundancy. The case of the letter is not standardized.For example, "Carlifornia" and "CARLIFORNIA" are referring to the same location and redundant.

**Standardizing the case of the letters in State:**
```{r}
df$State<-tolower(df$State)
capFirst <- function(s) {
  paste(toupper(substring(s, 1, 1)), substring(s, 2), sep = "")
}

df$State <- capFirst(df$State)
table(df$State)
```
<br />
From the results, we can see that the data redundancy is catered successfully.

<br />

### 4) Exploratory Data Analysis

In this section, we will drill deeper into the data for more insights. But first, we need to know what problems we want to solve and what questions to ask. Taking the POV of the owner of the Superstore:

-   Overview
    -   What is the monthly sales and profit since inception?
-   Overview - Increase Revenue
    -   Which product category has the highest sales?
    -   Which customer segment that contribute to the highest sales?
    -   Which region, state and city contribute to the highest sales?
-   Overview - Reduce Loss
    -   Which product category and subcategory that has the highest returned item? 
-   Correlation
    -   How the factors have influenced on each other?

<br />

#### <span style="text-decoration:underline">  Overview - Increase Revenue</span>

<br />
**1. Which product category with highest sales?** <br />

```{r}
df_category_sales <- df %>%
  select(Category, Sales) %>%
  group_by(Category) %>%
  summarise(Sales = sum(Sales))
```

```{r}
df_category_sales <- df_category_sales %>%
  mutate(Percentage = percent(df_category_sales$Sales/sum(df_category_sales$Sales)))
```

<span style="text-decoration:underline">  Bar Chart for Category by Sales Breakdown</span>

```{r}
bar_category_sales <- ggplot(data=df_category_sales, aes(x=Category, y=Sales, fill=Category)) +
  coord_cartesian(ylim = c(700000, 850000))+
  ggtitle("Category by Sales Breakdown") +
  geom_bar(stat="identity")+
  geom_text(aes(label=Percentage), vjust=1.6, color="white", size=3.5)+
  theme_minimal()
#bar_category_sales + scale_fill_manual(values=c("#999999", "#E69F00", "#56B4E9"))
bar_category_sales
```
<br />
<br />
**2. Which customer segment that contribute to the highest sales?** 

```{r}
df_segment_sales <- df %>%
  select(Segment, Sales) %>%
  group_by(Segment) %>%
  summarise(Sales = sum(Sales))

df_segment_sales[ , 1] <- apply(df_segment_sales[ , 1], 2,           
                    function(x) as.character(x))

sapply(df_segment_sales, class)

```

<span style="text-decoration:underline">  Inputting percentage column into the table</span>

```{r}
df_segment_sales <- df_segment_sales %>%
  mutate(Percentage = percent(df_segment_sales$Sales/sum(df_segment_sales$Sales)))
```

<span style="text-decoration:underline">  Pie Chart for CUstomer Segment Sales Contribution</span>

```{r}
ggplot(df_segment_sales, aes(x = "", y = Sales, fill = Segment)) +
  ggtitle("Customer Segment Sales Contribution") +
  geom_col() +
   geom_label(aes(label = Percentage ),
             position = position_stack(vjust = 0.5),
             show.legend = FALSE) +
  coord_polar(theta = "y")
```
<br />
<br />
**3. Which region, state and city contribute to the highest sales?** 

<span style="text-decoration:underline">  Region - Sales</span>

```{r}
df_region_sales <- df %>%
  select(Region, Sales) %>%
  group_by(Region) %>%
  summarise(Sales = sum(Sales))
```

<span style="text-decoration:underline">  Inputting percentage column into the table</span>

```{r}
df_region_sales <- df_region_sales %>%
    mutate(Percentage = percent(df_region_sales$Sales/sum(df_region_sales$Sales)))
```

<span style="text-decoration:underline">  Bar Chart for Region by Sales</span>

```{r}
bar_region_sales <- ggplot(data=df_region_sales, aes(x=Region, y=Sales, fill=Region)) +
  coord_cartesian(ylim = c(300000, 800000))+
  ggtitle("Region by Sales Breakdown") +
  geom_bar(stat="identity")+
  geom_text(aes(label=Percentage), vjust=1.6, color="white", size=3.5)+
  theme_minimal()
#bar_region_sales + scale_fill_manual(values=c("#999999", "#E69F00", "#56B4E9","#f5ad42"))
bar_region_sales
```

<span style="text-decoration:underline">  State - Sales</span>

```{r}
df_state_sales <- df %>%
  select(State, Sales) %>%
  group_by(State) %>%
  summarise(Sales = sum(Sales))

df_state_sales <- df_state_sales[order(-df_state_sales$Sales),]
```

```{r}
df_state_sales <- df_state_sales %>%
  mutate(Percentage = percent(df_state_sales$Sales/sum(df_state_sales$Sales),accuracy = 0.01))
```

<span style="text-decoration:underline">  Horizontal Bar Chart for Top 10 Regions by Sales</span>

```{r}
bar_state_sales <- ggplot(data=df_state_sales[1:10,], aes(x=State, y=Sales, fill=State)) +
  #coord_cartesian(ylim = c(300000, 800000))+
  geom_bar(stat="identity")+
  ggtitle("Top 10 Regions by Sales Breakdown") +
  geom_text(aes(label=Percentage), hjust=1.3, vjust=0.4, color="white", size=3)+
  theme_minimal()+
  coord_flip()
#bar_region_sales + scale_fill_manual(values=c("#999999", "#E69F00", "#56B4E9","#f5ad42"))
bar_state_sales
```

<span style="text-decoration:underline">  City - Sales</span>

```{r}
df_city_sales <- df %>%
  select(City, Sales) %>%
  group_by(City) %>%
  summarise(Sales = sum(Sales))

df_city_sales <- df_city_sales[order(-df_city_sales$Sales),]
```

```{r}
df_city_sales <- df_city_sales %>%
  mutate(Percentage = percent(df_city_sales$Sales/sum(df_city_sales$Sales),accuracy = 0.01))
```

<span style="text-decoration:underline">  Horizontal Bar Chart for Top 10 City by Sales</span>

```{r}
bar_city_sales <- ggplot(data=df_city_sales[1:10,], aes(x=City, y=Sales, fill=City)) +
  geom_bar(stat="identity")+
  ggtitle("Sales by Category Breakdown") +
  geom_text(aes(label=Percentage), hjust=1.3, vjust=0.4, color="white", size=3)+
  theme_minimal()+
  coord_flip()

bar_city_sales
```

<br />


#### <span style="text-decoration:underline">  Overview - Reduce Loss</span>

<br />
**1. Which product category and subcategory that has the highest returned item?** <br />

<span style="text-decoration:underline">  Category and Sub-Category having highest returned items</span>

```{r}
# Join orders and returns table
joined_df <- df_order %>% inner_join(df_return, 
                                     by = "Order ID")
```

<span style="text-decoration:underline">  Category Having Highest Returns</span>

```{r}
res_1 <- joined_df %>%
  filter(Returned == "Yes") %>%
  group_by(Category)%>%
  summarise(Total_Returns = n()) 

ggplot(data = res_1, 
       aes(x = Category, 
           y = Total_Returns, 
           fill = Category)) +
  geom_bar(stat="identity")+
  ggtitle("Returns By Category") +
  geom_text(aes(label = Total_Returns), hjust=1.3, vjust=0.4, color="white", size=3)+
  theme_minimal()
```

<span style="text-decoration:underline">  Sub-Category Having Highest Returns</span>

```{r}
res_2 <- joined_df %>%
  filter(Returned == "Yes") %>%
  group_by(`Sub-Category`)%>%
  summarise(Total_Returns = n())

ggplot(data = res_2, 
       aes(x = `Sub-Category`, 
           y = Total_Returns, 
           fill = `Sub-Category`)) +
  geom_bar(stat="identity")+
  ggtitle("Returns By Sub-Category") +
  geom_text(aes(label = Total_Returns), 
            hjust= 1.4, 
            vjust=0.5,
            color="white", 
            size=3)+
  theme_minimal() + 
  coord_flip()
```

<br />

#### <span style="text-decoration:underline">  Label Encoder</span>
```{r}
label <- LabelEncoder$new()
df$Segment <- label$fit_transform(df$Segment)
df$Region <- label$fit_transform(df$Region)
df$Category <- label$fit_transform(df$Category)
df$`Sub-Category` <- label$fit_transform(df$`Sub-Category`)
df$`Returned` <- label$fit_transform(df$`Returned`)
df$`Ship Mode` <- label$fit_transform(df$`Ship Mode`)
df$`City` <- label$fit_transform(df$`City`)
df$`State` <- label$fit_transform(df$`State`)

head(df)
```

<br />


#### <span style="text-decoration:underline">  Heat Map Correlation Matrix</span>
```{r}
set.seed(7)
correlationMatrix <- cor(df[,1:11])
cm <- melt(correlationMatrix)
ggplot(data = cm, aes(x=Var1, y=Var2,fill=value)) + geom_tile()
print(correlationMatrix)
```

<br />

### 5) Machine Learning & Assessment

### a - Linear Regression 
Based on the correlation analysis, we can see that "Sales" has a high positive correlation with dependent variable "Profit" 

```{r}
df_sales_profit <- df %>%
  select(Sales,Profit)
```

Let’s have a look at our model fitted to our data for sales and profit.  
```{r, warning=FALSE, error=FALSE, message=FALSE}
ggplot(data = df_sales_profit, aes(x = Sales, y = Profit)) +
geom_point() +
stat_smooth(method = "lm", col = "dodgerblue3") +
theme(panel.background = element_rect(fill = "white"),
axis.line.x=element_line(),
axis.line.y=element_line()) +
ggtitle("Linear Model Fitted to Data")
```

Create training set indices with 80% of data
```{r}
#For reproducibility
set.seed(100)
# Create index for testing and training data
inTrain <- createDataPartition(y = df_sales_profit$Profit, 
                               p = 0.8, list = FALSE)
# subset Sales & Profit data to training
salesprofit_training <- df_sales_profit[inTrain,]
# subset the rest to test
salesprofit_testing <- df_sales_profit[-inTrain,]

```

Build a linear regression model relating Sales and Profit. 

Whether we can use our model to make predictions will depend on:
<ol>
<li>Whether we can reject the null hypothesis that there is no relationship between our variables.</li>
<li>The model is a good fit for our data. </li>
</ol>
```{r}
linear_fit <- lm(Profit ~ Sales, data = salesprofit_training)
summary(linear_fit)
```

Based on the result summary shown above, is the hypothesis supported?
- Since the p-value is smaller than 0.05 as the cutoff for significance, we reject Ho . We can reject the null hypothesis in favor of believing there to be a relationship between Sales and Profit. 

#### <span style="text-decoration:underline">  Prediction </span>
```{r}
pred = predict(linear_fit,salesprofit_testing)
head(pred)
res<-residuals(linear_fit) # Find the residuals
res<-as.data.frame(res) # Convert the residual into a dataframe
head(res) # Prints the residuals
```

```{r}
# compare the predicted vs actual values

results<-cbind(pred,salesprofit_testing$Profit)

colnames(results)<-c('predicted','real')

results<-as.data.frame(results)

head(results)
```
```{r}
# Let’s now, compare the predicted vs actual values.
# The output of the above command is shown below in a graph that shows the predicted Profit.

plot(salesprofit_testing$Profit, type = 'l', lty = 1.8, col = "red")

#Now let’s plot our test revenue with the following command:
lines(pred, type = "l", col = "blue") 
```
```{r}
# Calculating the accuracy of this model

rmse <- sqrt(mean(pred-df_sales_profit$Profit)^2) 
# Root Mean Square Error is the standard deviation of the residuals

rmse
```
<br />

#### b - Classification For Ship Mode Using Decision Tree:

```{r}
# Remove insignificant variables
joined_df <- joined_df[, -which(names(joined_df) %in% c("Row ID",
                                      "Order ID",
                                      "Ship Date",
                                      "Order Date",
                                      "Customer ID",
                                      "Customer Name",
                                      "Postal Code",
                                      "Product ID",
                                      "Product Name",
                                      "Returned",
                                      "Country",
                                      "State",
                                      "City"))]
# Check structure of final variable
str(joined_df)
```
```{r}
library(superml)
# Label encode categorical variables
label <- LabelEncoder$new()
joined_df$Segment <- label$fit_transform(joined_df$Segment)
joined_df$Region <- label$fit_transform(joined_df$Region)
joined_df$Category <- label$fit_transform(joined_df$Category)
joined_df$`Sub-Category` <- label$fit_transform(joined_df$`Sub-Category`)

# Function for normalization
min_max_norm <- function(x) {
    (x - min(x)) / (max(x) - min(x))
  }

#apply Min-Max normalization on the dataset
joined_df[, 6:7] <- as.data.frame(lapply(joined_df[, 6:7], min_max_norm))
joined_df$Profit <- min_max_norm(joined_df$Profit)
head(joined_df)
```
```{r}
colSums(is.na(joined_df))
```


```{r}
# Split data into training and testing sets.
set.seed(124)
split1<- sample(c(rep(0, 0.7 * nrow(joined_df)), rep(1, 0.3 * nrow(joined_df))))
train <- joined_df[split1 == 0, ] 
test <- joined_df[split1== 1, ]
```

```{r}
# Fit decision tree model.
set.seed(123)
fit <- rpart(`Ship Mode` ~., 
             data = train, 
             method = 'class')
```

```{r}
# Evaluate performance on test set.
predict_unseen <- predict(fit, 
                          test, 
                          type = 'class')
table_mat <- table(test$`Ship Mode`, 
                   predict_unseen)
confusionMatrix(table_mat)
```